# test_knowledge_base.py
"""Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©"""

import asyncio

print("=" * 60)
print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©")
print("=" * 60)

from knowledge_base.vector_store.embeddings import EmbeddingsGenerator
from knowledge_base.vector_store.memory_store import MemoryVectorStore
from knowledge_base.retrieval.hybrid_search import HybridSearchEngine

async def main():
    # 1. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
    print("\n1ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª...")
    embeddings = EmbeddingsGenerator()
    vector_store = MemoryVectorStore()
    search_engine = HybridSearchEngine(embeddings, vector_store)
    print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª")
    
    # 2. Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªÙ†Ø¯Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    print("\n2ï¸âƒ£ Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªÙ†Ø¯Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©...")
    
    test_docs = [
        {
            "id": "doc1",
            "content": "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù‡Ùˆ ÙØ±Ø¹ Ù…Ù† Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ ÙŠÙ‡ØªÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø£Ù†Ø¸Ù…Ø© Ø°ÙƒÙŠØ© Ù‚Ø§Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„Ù….",
            "metadata": {"type": "general", "language": "ar"}
        },
        {
            "id": "doc2",
            "content": "ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ¹Ø¯Ø¯Ø© ÙÙŠ Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ø·Ø¨ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„ØµÙ†Ø§Ø¹Ø©.",
            "metadata": {"type": "general", "language": "ar"}
        },
        {
            "id": "doc3",
            "content": "Machine Learning is a subset of AI that focuses on learning from data.",
            "metadata": {"type": "general", "language": "en"}
        },
        {
            "id": "doc4",
            "content": "Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ© ØªÙˆØ¶Ø­ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø§Ù„ÙŠ Ù„Ù„Ø´Ø±ÙƒØ§Øª Ø®Ù„Ø§Ù„ ÙØªØ±Ø© Ù…Ø­Ø¯Ø¯Ø©.",
            "metadata": {"type": "financial", "language": "ar"}
        }
    ]
    
    # ØªÙˆÙ„ÙŠØ¯ embeddings ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
    for doc in test_docs:
        embedding = await embeddings.generate(doc["content"])
        await vector_store.add_document(
            doc_id=doc["id"],
            content=doc["content"],
            embedding=embedding,
            metadata=doc["metadata"]
        )
    
    print(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(test_docs)} Ù…Ø³ØªÙ†Ø¯Ø§Øª")
    
    # 3. Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    print("\n3ï¸âƒ£ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø®Ø²Ù†:")
    stats = vector_store.get_stats()
    print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª: {stats['total_documents']}")
    for idx, count in stats['indexes'].items():
        print(f"   {idx}: {count} Ù…Ø³ØªÙ†Ø¯Ø§Øª")
    
    # 4. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
    print("\n4ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«...")
    
    queries = [
        "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ",
        "Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙÙŠ Ø§Ù„Ø·Ø¨",
        "Machine Learning",
        "Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ©"
    ]
    
    for query in queries:
        print(f"\nğŸ” Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: '{query}'")
        
        results = await search_engine.search(
            query=query,
            top_k=2,
            index_name="general"
        )
        
        print(f"   Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {len(results)}")
        
        for i, result in enumerate(results, 1):
            print(f"\n   Ù†ØªÙŠØ¬Ø© {i}:")
            print(f"      Ø§Ù„Ù…Ø¹Ø±Ù: {result['id']}")
            print(f"      Ø§Ù„Ø¯Ø±Ø¬Ø©: {result['combined_score']:.3f}")
            print(f"      Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø­Ø«: {result.get('search_types', [])}")
            print(f"      Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {result['content'][:80]}...")
    
    # 5. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    print("\n\n5ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ† Embeddings...")
    
    text1 = "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
    text2 = "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"
    text3 = "Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ©"
    
    emb1 = await embeddings.generate(text1)
    emb2 = await embeddings.generate(text2)
    emb3 = await embeddings.generate(text3)
    
    sim_1_2 = embeddings.cosine_similarity(emb1, emb2)
    sim_1_3 = embeddings.cosine_similarity(emb1, emb3)
    
    print(f"   Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ† '{text1}' Ùˆ '{text2}': {sim_1_2:.3f}")
    print(f"   Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ† '{text1}' Ùˆ '{text3}': {sim_1_3:.3f}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª!")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())